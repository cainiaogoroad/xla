load("@local_config_cuda//cuda:build_defs.bzl", "cuda_library")

licenses(["notice"])

FLASH_ATTN_COPTS = [
    "-U__CUDA_NO_HALF_OPERATORS__",
    "-U__CUDA_NO_HALF_CONVERSIONS__",
    "-U__CUDA_NO_HALF2_OPERATORS__",
    "-U__CUDA_NO_BFLOAT16_CONVERSIONS__",
    "-nvcc_options=expt-relaxed-constexpr",
    "-nvcc_options=expt-extended-lambda",
    "-nvcc_options=use_fast_math",
]

cuda_library(
    name = "flash_attn_src",
    hdrs = [
        "csrc/flash_attn/src/alibi.h",
        "csrc/flash_attn/src/block_info.h",
        "csrc/flash_attn/src/dropout.h",
        "csrc/flash_attn/src/flash_bwd_kernel.h",
        "csrc/flash_attn/src/flash_bwd_launch_template.h",
        "csrc/flash_attn/src/flash_bwd_preprocess_kernel.h",
        "csrc/flash_attn/src/flash_fwd_kernel.h",
        "csrc/flash_attn/src/flash_fwd_launch_template.h",
        "csrc/flash_attn/src/flash.h",
        "csrc/flash_attn/src/kernel_traits.h",
        "csrc/flash_attn/src/mask.h",
        "csrc/flash_attn/src/philox.cuh",
        "csrc/flash_attn/src/rotary.h",
        "csrc/flash_attn/src/softmax.h",
        "csrc/flash_attn/src/static_switch.h",
        "csrc/flash_attn/src/utils.h",
    ],
    srcs = [
        "csrc/flash_attn/src/flash_bwd_hdim128_bf16_sm80.cu.cc",
        "csrc/flash_attn/src/flash_bwd_hdim128_fp16_sm80.cu.cc",
        "csrc/flash_attn/src/flash_bwd_hdim160_bf16_sm80.cu.cc",
        "csrc/flash_attn/src/flash_bwd_hdim160_fp16_sm80.cu.cc",
        "csrc/flash_attn/src/flash_bwd_hdim192_bf16_sm80.cu.cc",
        "csrc/flash_attn/src/flash_bwd_hdim192_fp16_sm80.cu.cc",
        "csrc/flash_attn/src/flash_bwd_hdim224_bf16_sm80.cu.cc",
        "csrc/flash_attn/src/flash_bwd_hdim224_fp16_sm80.cu.cc",
        "csrc/flash_attn/src/flash_bwd_hdim256_bf16_sm80.cu.cc",
        "csrc/flash_attn/src/flash_bwd_hdim256_fp16_sm80.cu.cc",
        "csrc/flash_attn/src/flash_bwd_hdim32_bf16_sm80.cu.cc",
        "csrc/flash_attn/src/flash_bwd_hdim32_fp16_sm80.cu.cc",
        "csrc/flash_attn/src/flash_bwd_hdim64_bf16_sm80.cu.cc",
        "csrc/flash_attn/src/flash_bwd_hdim64_fp16_sm80.cu.cc",
        "csrc/flash_attn/src/flash_bwd_hdim96_bf16_sm80.cu.cc",
        "csrc/flash_attn/src/flash_bwd_hdim96_fp16_sm80.cu.cc",
        "csrc/flash_attn/src/flash_fwd_hdim128_bf16_sm80.cu.cc",
        "csrc/flash_attn/src/flash_fwd_hdim128_fp16_sm80.cu.cc",
        "csrc/flash_attn/src/flash_fwd_hdim160_bf16_sm80.cu.cc",
        "csrc/flash_attn/src/flash_fwd_hdim160_fp16_sm80.cu.cc",
        "csrc/flash_attn/src/flash_fwd_hdim192_bf16_sm80.cu.cc",
        "csrc/flash_attn/src/flash_fwd_hdim192_fp16_sm80.cu.cc",
        "csrc/flash_attn/src/flash_fwd_hdim224_bf16_sm80.cu.cc",
        "csrc/flash_attn/src/flash_fwd_hdim224_fp16_sm80.cu.cc",
        "csrc/flash_attn/src/flash_fwd_hdim256_bf16_sm80.cu.cc",
        "csrc/flash_attn/src/flash_fwd_hdim256_fp16_sm80.cu.cc",
        "csrc/flash_attn/src/flash_fwd_hdim32_bf16_sm80.cu.cc",
        "csrc/flash_attn/src/flash_fwd_hdim32_fp16_sm80.cu.cc",
        "csrc/flash_attn/src/flash_fwd_hdim64_bf16_sm80.cu.cc",
        "csrc/flash_attn/src/flash_fwd_hdim64_fp16_sm80.cu.cc",
        "csrc/flash_attn/src/flash_fwd_hdim96_bf16_sm80.cu.cc",
        "csrc/flash_attn/src/flash_fwd_hdim96_fp16_sm80.cu.cc",
        "csrc/flash_attn/src/flash_fwd_split_hdim128_bf16_sm80.cu.cc",
        "csrc/flash_attn/src/flash_fwd_split_hdim128_fp16_sm80.cu.cc",
        "csrc/flash_attn/src/flash_fwd_split_hdim160_bf16_sm80.cu.cc",
        "csrc/flash_attn/src/flash_fwd_split_hdim160_fp16_sm80.cu.cc",
        "csrc/flash_attn/src/flash_fwd_split_hdim192_bf16_sm80.cu.cc",
        "csrc/flash_attn/src/flash_fwd_split_hdim192_fp16_sm80.cu.cc",
        "csrc/flash_attn/src/flash_fwd_split_hdim224_bf16_sm80.cu.cc",
        "csrc/flash_attn/src/flash_fwd_split_hdim224_fp16_sm80.cu.cc",
        "csrc/flash_attn/src/flash_fwd_split_hdim256_bf16_sm80.cu.cc",
        "csrc/flash_attn/src/flash_fwd_split_hdim256_fp16_sm80.cu.cc",
        "csrc/flash_attn/src/flash_fwd_split_hdim32_bf16_sm80.cu.cc",
        "csrc/flash_attn/src/flash_fwd_split_hdim32_fp16_sm80.cu.cc",
        "csrc/flash_attn/src/flash_fwd_split_hdim64_bf16_sm80.cu.cc",
        "csrc/flash_attn/src/flash_fwd_split_hdim64_fp16_sm80.cu.cc",
        "csrc/flash_attn/src/flash_fwd_split_hdim96_bf16_sm80.cu.cc",
        "csrc/flash_attn/src/flash_fwd_split_hdim96_fp16_sm80.cu.cc",
    ],
    # https://github.com/Dao-AILab/flash-attention/blob/v2.5.9.post1/setup.py#L193-L199
    copts = FLASH_ATTN_COPTS,
    strip_include_prefix = "csrc/flash_attn/src",
    deps = [
        "@torch//:headers",
        "@torch//:libtorch",
        "@torch//:libc10",
        "@cutlass_for_flash_attn//:cutlass",
        "@local_config_cuda//cuda:cuda_headers",
    ],
    visibility = ["//visibility:private"],
)

cuda_library(
    name = "flash_attn",
    hdrs = [
        "csrc/flash_attn/flash_api.h",
    ],
    srcs = [
        "csrc/flash_attn/flash_api.cpp",
    ],
    copts = FLASH_ATTN_COPTS,
    include_prefix = "flash_attn",
    strip_include_prefix = "csrc/flash_attn",
    deps = [
        ":flash_attn_src"
    ],
    visibility = ["//visibility:public"],
)